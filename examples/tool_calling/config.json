{
  "clients": {
    "openai": {
      "provider": "openai"
    },
    "ollama": {
      "provider": "ollama",
      "base_url": "http://localhost:11434"
    }
  },
  "models": {
    "ollama-llama3.1": {
      "client": "ollama",
      "model": "llama3.1:8b"
    },
    "ollama-qwen2.5-7b-instruct": {
      "client": "ollama",
      "model": "qwen2.5:7b-instruct"
    },
    "gpt-5-mini": {
      "client": "openai",
      "model": "gpt-5-mini"
    },
    "gpt-5-nano": {
      "client": "openai",
      "model": "gpt-5-nano"
    },
    "gpt-4.1-mini": {
      "client": "openai",
      "model": "gpt-4.1-mini"
    },
    "gpt-4.1-nano": {
      "client": "openai",
      "model": "gpt-4.1-nano"
    }
  },
  "servers": {
    "math": {
      "command": "python",
      "args": ["../../mcp-servers/math/server.py"]
    },
    "time": {
      "command": "uvx",
      "args": ["casual-mcp-server-time"],
      "env": {
        "LOCAL_TIME_ZONE": "Asia/Bangkok"
      }
    },
    "weather": {
      "command": "uvx",
      "args": ["casual-mcp-server-weather"]
    },
    "words": {
      "command": "uvx",
      "args": ["casual-mcp-server-words"]
    },
    "fetch": {
      "command": "npx",
      "args": ["-y", "@lmcc-dev/mult-fetch-mcp-server"],
      "env": {
        "MCP_LANG": "en"
      }
    }
  }
}
