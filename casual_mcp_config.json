{
    "models": {
        "ollama-llama3.1": {
            "provider": "ollama",
            "endpoint": "http://kovacs.jinkies.net:11434",
            "model": "llama3.1"
        },
        "ollama-phi-4-mini": {
            "provider": "ollama",
            "endpoint": "http://kovacs.jinkies.net:11434",
            "model": "phi4-tools"
        },
        "ollama-qwen2.5": {
            "provider": "ollama",
            "endpoint": "http://kovacs.jinkies.net:11434",
            "model": "qwen2.5"
        },
        "lm-phi-4-mini": {
            "provider": "ollama",
            "endpoint": "http://kovacs.jinkies.net:1234/v1",
            "model": "phi-4-mini-instruct",
            "template": "phi-4-mini-instruct-1"
        },
        "gpt-5": {
            "provider": "openai",
            "model": "gpt-5"
        },
        "gpt-5-mini": {
            "provider": "openai",
            "model": "gpt-5-mini"
        },
        "gpt-5-nano": {
            "provider": "openai",
            "model": "gpt-5-nano"
        },
        "gpt-4.1": {
            "provider": "openai",
            "model": "gpt-4.1"
        },
        "gpt-4.1-mini": {
            "provider": "openai",
            "model": "gpt-4.1-mini"
        },
        "gpt-4.1-nano": {
            "provider": "openai",
            "model": "gpt-4.1-nano"
        }
    },
    "servers": {
        "math": {
            "command": "python",
            "args": ["mcp-servers/math/server.py"]
        },
        "time": {
            "command": "uvx",
            "args": ["casual-mcp-server-time"]
        },
        "weather": {
            "command": "uvx",
            "args": ["casual-mcp-server-weather"]
        },
        "words": {
            "command": "uvx",
            "args": ["casual-mcp-server-words"]
        },
        "fetch": {
            "command": "npx",
            "args": ["-y", "@lmcc-dev/mult-fetch-mcp-server"],
            "env": {
                "MCP_LANG": "en"
            }
        }
    }
}