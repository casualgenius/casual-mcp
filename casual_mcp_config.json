{
    "models": {
        "ollama-llama3.1": {
            "provider": "ollama",
            "endpoint": "http://localhost:11434",
            "model": "llama3.1:8b"
        },
        "ollama-qwen2.5-7b-instruct": {
            "provider": "ollama",
            "endpoint": "http://localhost:11434",
            "model": "qwen2.5:7b-instruct"
        },
        "ollama-qwen2.5-7b-instruct-with-template": {
            "provider": "ollama",
            "endpoint": "http://localhost:11434",
            "model": "qwen2.5:7b-instruct",
            "template": "ollama-tools"
        },
        "gpt-5": {
            "provider": "openai",
            "model": "gpt-5"
        },
        "gpt-5-mini": {
            "provider": "openai",
            "model": "gpt-5-mini"
        },
        "gpt-5-nano": {
            "provider": "openai",
            "model": "gpt-5-nano"
        },
        "gpt-4.1": {
            "provider": "openai",
            "model": "gpt-4.1"
        },
        "gpt-4.1-mini": {
            "provider": "openai",
            "model": "gpt-4.1-mini"
        },
        "gpt-4.1-nano": {
            "provider": "openai",
            "model": "gpt-4.1-nano"
        }
    },
    "servers": {
        "math": {
            "command": "python",
            "args": ["mcp-servers/math/server.py"]
        },
        "time": {
            "command": "python",
            "args": ["mcp-servers/time-v2/server.py"]
        },
        "weather": {
            "command": "python",
            "args": ["mcp-servers/weather/server.py"]
        },
        "words": {
            "command": "python",
            "args": ["mcp-servers/words/server.py"]
        },
        "fetch": {
            "command": "npx",
            "args": ["-y", "@lmcc-dev/mult-fetch-mcp-server"],
            "env": {
                "MCP_LANG": "en"
            }
        }
    }
}